package graph

// This file will be automatically regenerated based on the schema, any resolver implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.66

import (
	"context"
	"djong-reader-engine/config"
	"djong-reader-engine/graph/model"
	"djong-reader-engine/graphqlutils"
	"fmt"
	"log"
	"time"
)

// SalesPipeline is the resolver for the salesPipeline field.
func (r *queryResolver) SalesPipeline(ctx context.Context, id string) (*model.SalesPipeline, error) {
	// print log

	graphqlutils.RequestLogger(ctx, "Query Education by id")

	var slsPln model.SalesPipeline
	var createdAt *time.Time
	err := config.DB.QueryRow(ctx, `
		SELECT id, value, estimated_close_date, comment, created_at, created_by, updated_at, updated_by, is_active
		FROM mst_sales_pipeline
		WHERE id=$1
	`, id).Scan(
		&slsPln.ID, &slsPln.Value, &slsPln.EstimatedCloseDate, &slsPln.Comment,
		&createdAt, &slsPln.CreatedBy, &slsPln.UpdatedAt, &slsPln.UpdatedBy, &slsPln.IsActive,
	)

	// ✅ Convert time.Time to model.Time
	if ts := model.TimeFromPtr(createdAt); ts != nil {
		slsPln.CreatedAt = time.Time(*ts)
	}

	if err != nil {
		log.Println("Error fetching SalesPipeline: ", err)
		return nil, err
	}

	graphqlutils.ResponseLogger(slsPln)

	return &slsPln, nil
}

// SalesPipelines is the resolver for the salesPipelines field.
func (r *queryResolver) SalesPipelines(ctx context.Context, first *int32, after *string, orderBy *model.SalesPipelineOrderByInput) (*model.SalesPipelineConnection, error) {
	graphqlutils.RequestLogger(ctx, "Query salesPipelines")

	var limit int32
	if first != nil {
		limit = *first
	} else {
		limit = 10 // default limit
	}

	// Initialize sorting parameters
	sortField := "end_date"
	sortDirection := "DESC"

	// Update sorting parameters based on orderBy input
	if orderBy != nil {
		if orderBy.EndDate != nil {
			sortField = "end_date"
			sortDirection = string(*orderBy.EndDate)
		}
		// Add additional fields as needed
	}

	var cursor string
	if after != nil {
		cursor = *after
	} else {
		cursor = ""
	}

	query := fmt.Sprintf(`
        SELECT id, value, estimated_close_date, comment, created_at, created_by, updated_at, updated_by, is_active
		FROM mst_sales_pipeline
        ORDER BY %s %s
		OFFSET $1
        LIMIT $2
    `, sortField, sortDirection)

	rows, err := config.DB.Query(ctx, query, cursor, limit)
	if err != nil {
		log.Println("Error fetching sales pipelines: ", err)
		return nil, err
	}

	defer rows.Close()

	var salesPipelines []*model.SalesPipeline
	var lastCursor string
	for rows.Next() {
		var slsPln model.SalesPipeline
		var createdAt *time.Time

		if err := rows.Scan(
			&slsPln.ID, &slsPln.Value, &slsPln.EstimatedCloseDate, &slsPln.Comment,
			&createdAt, &slsPln.CreatedBy, &slsPln.UpdatedAt, &slsPln.UpdatedBy, &slsPln.IsActive,
		); err != nil {
			log.Println("Error scanning SalesPipeline:", err)
			continue
		}

		// ✅ Convert time.Time to model.Time
		if ts := model.TimeFromPtr(createdAt); ts != nil {
			slsPln.CreatedAt = time.Time(*ts)
		}

		salesPipelines = append(salesPipelines, &slsPln)
		lastCursor = slsPln.ID
	}

	pageInfo := &model.PageInfo{
		EndCursor:   &lastCursor,
		HasNextPage: len(salesPipelines) == int(limit),
	}

	edges := make([]*model.SalesPipelineEdge, len(salesPipelines))
	for i, slsPln := range salesPipelines {
		edges[i] = &model.SalesPipelineEdge{
			Cursor: slsPln.ID,
			Node:   slsPln,
		}
	}
	var response = &model.SalesPipelineConnection{
		Edges:    edges,
		PageInfo: pageInfo,
	}

	graphqlutils.ResponseLogger(response)

	return response, nil
}

// Query returns QueryResolver implementation.
func (r *Resolver) Query() QueryResolver { return &queryResolver{r} }

type queryResolver struct{ *Resolver }
